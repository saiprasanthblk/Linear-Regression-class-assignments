cv.error=rep (0,5)
for (i in 1:5) {
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm (Auto ,glm .fit)$delta [1]
}
cv.error
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm (Auto ,glm .fit)$delta [1]
cv.error=rep (0,5)
for (i in 1:5)
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm (Auto ,glm .fit)$delta [1]
cv.error
cv.error=rep (0,5)
for (i in 1:5) {
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm (Auto ,glm .fit)$delta [1]
}
cv.error
cv.error=rep (0,5)
for (i in 1:5){
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm (Auto ,glm .fit)$delta [1]
}
cv.error
cv.error=rep (0,5)
i =1
for (i in 1:5) {
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm (Auto ,glm .fit)$delta [1]
}
cv.error
set.seed (17)
cv.error .10= rep (0 ,10)
for (i in 1:10) {
+ glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto)
+ cv.error .10[i]=cv.glm (Auto ,glm .fit ,K=10) $delta [1]
+ }
cv.error .10
cv.error=rep (0,5)
for (i in 1:5) {
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm (Auto ,glm .fit)$delta [1]
}
cv.error
cv.error=rep (0,5)
for (i in 1:5) {
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm (Auto ,glm .fit)$delta [1]
}
cv.error
cv.error=rep (0,5)
for (i in 1:5) {
glm.fit=glm(mpg~poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm (Auto ,glm .fit)$delta[1]
}
cv.error
cv.error=rep (0,5)
for (i in 1:5) {
glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
cv.error[i]=cv.glm (Auto,glm.fit)$delta[1]
}
cv.error
set.seed(17)
cv.error.10= rep (0 ,10)
for (i in 1:10) {
glm.fit=glm(mpg∼poly(horsepower,i),data=Auto)
cv.error .10[i]=cv.glm (Auto,glm.fit,K=10)$delta[1]
}
cv.error.10
set.seed(17)
cv.error.10=rep(0 ,10)
for (i in 1:10) {
glm.fit=glm(mpg∼poly(horsepower,i),data=Auto)
cv.error .10[i]=cv.glm (Auto,glm.fit,K=10)$delta[1]
}
cv.error.10
set.seed(17)
cv.error.10=rep(0,10)
for (i in 1:10) {
glm.fit=glm(mpg∼poly(horsepower,i),data=Auto)
cv.error .10[i]=cv.glm (Auto,glm.fit,K=10)$delta[1]
}
cv.error.10
set.seed(17)
cv.error.10=rep(0,10)
for (i in 1:10) {
glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
cv.error .10[i]=cv.glm (Auto,glm.fit,K=10)$delta[1]
}
cv.error.10
set.seed(17)
cv.error.10=rep(0,10)
for (i in 1:10) {
glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
cv.error.10[i]=cv.glm (Auto,glm.fit,K=10)$delta[1]
}
cv.error.10
alpha.fn=function (data ,index){
X=data$X[index]
Y=data$Y[index]
return ((var(Y)-cov(X,Y))/(var(X)+var(Y) -2* cov(X,Y)))
}
alpha.fn(Portfolio ,1:100)
set.seed (1)
alpha.fn(Portfolio ,sample (100 ,100 , replace =T))
boot(Portfolio ,alpha.fn,R=1000)
boot(Auto ,boot.fn ,1000)
# ORDINARY NONPARAMETRIC BOOTSTRAP
#Call:
boot(data = Auto , statistic = boot.fn, R = 1000)
# Bootstrap Statistics :
#  original bias std. error
boot(Auto ,boot.fn ,1000)
# ORDINARY NONPARAMETRIC BOOTSTRAP
#Call:
#  boot(data = Auto , statistic = boot.fn, R = 1000)
# Bootstrap Statistics :
boot(data = Auto , statistic = boot.fn, R = 1000)
boot(Auto ,boot.fn ,1000)
boot(data = Portfolio , statistic = alpha.fn, R = 1000)
boot.fn=function (data ,index )
return (coef(lm(mpg∼horsepower ,data=data ,subset=index)))
boot.fn(Auto ,1:392)
set.seed(1)
boot.fn(Auto ,sample (392 ,392 , replace =T))
boot.fn(Auto ,sample (392 ,392 , replace =T))
boot(Auto ,boot.fn ,1000)
boot.fn=function (data ,index )
coefficients(lm(mpg∼horsepower +I( horsepower ^2) ,data=data ,
subset =index))
set.seed (1)
boot(Auto ,boot.fn ,1000)
x <- 1:100000
plot(x, 1 - (1 - 1/x)^x)
x = c(1:100000)
plot(x, 1 - (1 - 1/x)^x)
library(ISLR)
attach(Default)
set.seed(1)
fit.glm <- glm(default ~ income + balance, data = Default, family = "binomial")
summary(fit.glm)
train <- sample(dim(Default)[1], dim(Default)[1] / 2)
fit.glm <- glm(default ~ income + balance, data = Default, family = "binomial", subset = train)
summary(fit.glm)
train <- sample(dim(Default)[1], dim(Default)[1] / 2)
model2.glm <- glm(default ~ income + balance, data = Default, family = "binomial", subset = train)
summary(model2.glm)
probability <- predict(fit.glm, newdata = Default[-train, ], type = "response")
pred.glm <- rep("No", length(probability))
pred.glm[probability > 0.5] <- "Yes"
mean(pred.glm != Default[-train, ]$default)
train <- sample(dim(Default)[1], dim(Default)[1] / 2)
fit.glm <- glm(default ~ income + balance, data = Default, family = "binomial", subset = train)
probs <- predict(fit.glm, newdata = Default[-train, ], type = "response")
pred.glm <- rep("No", length(probs))
pred.glm[probs > 0.5] <- "Yes"
mean(pred.glm != Default[-train, ]$default)
train <- sample(dim(Default)[1], dim(Default)[1] / 2)
fit.glm <- glm(default ~ income + balance, data = Default, family = "binomial", subset = train)
probs <- predict(fit.glm, newdata = Default[-train, ], type = "response")
pred.glm <- rep("No", length(probs))
pred.glm[probs > 0.5] <- "Yes"
mean(pred.glm != Default[-train, ]$default)
train <- sample(dim(Default)[1], dim(Default)[1] / 2)
fit.glm <- glm(default ~ income + balance, data = Default, family = "binomial", subset = train)
probs <- predict(fit.glm, newdata = Default[-train, ], type = "response")
pred.glm <- rep("No", length(probs))
pred.glm[probs > 0.5] <- "Yes"
mean(pred.glm != Default[-train, ]$default)
train <- sample(dim(Default)[1], dim(Default)[1] / 2)
model3.glm <- glm(default ~ income + balance + student, data = Default, family = "binomial", subset = train)
pred.glm <- rep("No", length(probability))
probability <- predict(model3.glm, newdata = Default[-train, ], type = "response")
pred.glm[probability > 0.5] <- "Yes"
mean(pred.glm != Default[-train, ]$default)
train <- sample(dim(Default)[1], dim(Default)[1] / 2)
model3.glm <- glm(default ~ income + balance + student, data = Default, family = "binomial", subset = train)
pred.glm <- rep("No", length(probability))
probability <- predict(model3.glm, newdata = Default[-train, ], type = "response")
pred.glm[probability > 0.5] <- "Yes"
mean(pred.glm != Default[-train, ]$default)
summary (lm(mpg∼horsepower +I(horsepower ^2) ,data=Auto))$coef
set.seed(1)
y <- rnorm(100)
x <- rnorm(100)
y <- x - 2 * x^2 + rnorm(100)
plot(x, y)
library(boot)
set.seed(1)
Data <- data.frame(x, y)
fit.glm.1 <- glm(y ~ x)
cv.glm(Data, fit.glm.1)$delta[1]
fit.glm.2 <- glm(y ~ poly(x, 2))
cv.glm(Data, fit.glm.2)$delta[1]
fit.glm.3 <- glm(y ~ poly(x, 3))
cv.glm(Data, fit.glm.3)$delta[1]
fit.glm.4 <- glm(y ~ poly(x, 4))
cv.glm(Data, fit.glm.4)$delta[1]
library(boot)
set.seed(1)
Data <- data.frame(x, y)
model1.glm <- glm(y ~ x)
cv.glm(Data, model1.glm)$delta[1]
model2.glm <- glm(y ~ poly(x, 2))
cv.glm(Data, fit.model2)$delta[1]
model2.glm <- glm(y ~ poly(x, 2))
cv.glm(Data, fit.model2.glm)$delta[1]
model2.glm <- glm(y ~ poly(x, 2))
cv.glm(Data, model2.glm)$delta[1]
model3.glm <- glm(y ~ poly(x, 3))
cv.glm(Data, model3.glm)$delta[1]
model4.glm <- glm(y ~ poly(x, 4))
cv.glm(Data, model4.glm)$delta[1]
set.seed(10)
model1.glm <- glm(y ~ x)
cv.glm(Data, model1.glm)$delta[1]
model2.glm <- glm(y ~ poly(x, 2))
cv.glm(Data, model2.glm)$delta[1]
model3.glm <- glm(y ~ poly(x, 3))
cv.glm(Data, model3.glm)$delta[1]
fit.glm.4 <- glm(y ~ poly(x, 4))
cv.glm(Data, fit.glm.4)$delta[1]
model4.glm <- glm(y ~ poly(x, 4))
cv.glm(Data, model4.glm)$delta[1]
summary(model2.glm)
summary(model2.glm)
summary(model3.glm)
summary(model4.glm)
summary(model2.glm)
library(readxl)
data1 <- read_excel("data-table-B1.xls")
setwd("C:/Users/Prasanth/Downloads/M.S. Data Science Academics/1st Sem/Linear Regression/Assignments/Assignment 4")
data1 <- read_excel("data-table-B1.xls")
data1 <- read_excel("data-table-B1.xls")
setwd("C:/Users/Prasanth/Downloads/M.S. Data Science Academics/1st Sem/Linear Regression/Assignments/Assignment 4")
data1 <- read_excel("data-table-B1-1.xls")
View(data1)
lm <- lm(y~., data=data) #Run the linear regression
data <- as.data.fram(read_excel("data-table-B1-1.xls"))
data <- as.data.frame(read_excel("data-table-B1-1.xls"))
lm <- lm(y~., data=data) #Run the linear regression
qqnorm(rstudent(lm))
qqline(rstudent(lm))
Predicted_values = predict(lm, newdata = data)
Predicted_values = predict(lm, newdata = data)
standardized = rstandard(lm)
plot(Predicted_values, standardized)
View(data)
library(readxl)
data <- as.data.frame(read_excel("data-table-B1-1.xls"))
lm <- lm(y~., data=data) #Run the linear regression
qqnorm(rstudent(lm))
qqline(rstudent(lm))
Predicted_values = predict(lm, newdata = data)
standardized = rstandard(lm)
plot(Predicted_values, standardized)
plot(data$x1, standardized)
plot(data$x2, standardized)
plot(data$x3, standardized)
plot(data$x4, standardized)
plot(data$x5, standardized)
plot(data$x6, standardized)
plot(data$x7, standardized)
plot(data$x8, standardized)
plot(data$x9, standardized)
plot(data$x2, standardized) # seems to be alright
studentized <- studres(lm); studentized #Find the studentized residuals
library("MASS") #need this package to calculate the studentized residual with studres()
studentized <- studres(lm); studentized #Find the studentized residuals
rstudent <-rstudent(lm); rstudent #Find the R-student residuals
studentized <- studres(lm); studentized #Find the studentized residuals
rstudent <-rstudent(lm); rstudent #Find the R-student residuals
plot(data$y, studentized)
plot(data$y, rstudent)
data2 <- as.data.frame(read_excel("data-table-B3-1.xls"))
lm2 <- lm(y~., data=data2) #Run the linear regression
qqnorm(rstudent(lm2))
qqline(rstudent(lm2))
Predicted_values = predict(lm, newdata = data2)
standardized = rstandard(lm2)
plot(Predicted_values, standardized)
Predicted_values = predict(lm2, newdata = data2)
standardized = rstandard(lm2)
plot(Predicted_values, standardized)
Predicted_values = predict(lm2, newdata = data2)
standardized = rstandard(lm2)
View(data2)
standardized = rstandard(lm2)
plot(Predicted_values, standardized)
data <- as.data.frame(read_excel("data-table-B1-1.xls"))
lm <- lm(y~., data=data) #Run the linear regression
Predicted_values = predict(lm, newdata = data)
standardized = rstandard(lm)
plot(Predicted_values, standardized)
standardized = rstandard(lm)
data2 <- as.data.frame(read_excel("data-table-B3-1.xls"))
lm2 <- lm(y~., data=data2) #Run the linear regression
Predicted_values = predict(lm2, newdata = data2)
standardized = rstandard(lm2)
plot(Predicted_values, standardized)
Predicted_values = predict(lm2, newdata = data2)
standardized = rstandard(lm2)
plot(Predicted_values[1:30], standardized)
Predicted_values = predict(lm2, newdata = data2)
standardized = rstandard(lm2)
View(data2)
standardized = rstandard(lm2)
standardized
data2[is.na(data2)] <- 0
lm2 <- lm(y~., data=data2) #Run the linear regression
Predicted_values = predict(lm2, newdata = data2)
standardized = rstandard(lm2)
plot(Predicted_values, standardized)
library("MASS") #need this package to calculate the studentized residual with studres()
studentized <- studres(lm2); studentized #Find the studentized residuals
rstudent <-rstudent(lm2); rstudent #Find the R-student residuals
plot(data$y, studentized) # there is a point beyond -2 (the first point)
data2 <- as.data.frame(read_excel("data-table-B3-1.xls"))
data2[is.na(data2)] <- 0 # i noticed there a couple of NA's
lm2 <- lm(y~., data=data2) #Run the linear regression
plot(data$y, studentized) # there is a point beyond -2 (the first point)
plot(data2$y, studentized) # there is a point beyond -2 (the first point)
plot(data2$y, rstudent) # its the same. The first point is beyond -2
Month <- c('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec')
Temperature <- c(21, 24, 32, 47, 50, 59, 68, 74, 62, 50, 41, 30)
Usage <- c(185.79, 214.47, 288.03, 424.84, 454.68, 539.03, 621.55, 675.06, 562.03, 452.93, 369.95, 273.98)
dat <- data.frame(Month, Temperature, Usage)
dat$Month <- as.factor(dat$Month)
lm3 <- lm(Usage ~ Temperature, data = dat)
qqnorm(rstudent(lm2))
qqline(rstudent(lm2))
Predicted_values = predict(lm3, newdata = dat)
standardized = rstandard(lm3)
plot(Predicted_values, standardized)
View(dat)
plot(dat$Month, standardized)
data4 <- as.data.frame(read_excel("data-table-B5-1.xls"))
View(data4)
lm4 <- lm(y ~ data4$x6, data=data4) #Run the linear regression
lm5 <- lm(y~ data4$x7, data=data4) #Run the linear regression
qqnorm(rstudent(lm4))
qqline(rstudent(lm4))
qqnorm(rstudent(lm5))
qqline(rstudent(lm5))
Predicted_values = predict(lm4, newdata = data4)
standardized = rstandard(lm4)
plot(Predicted_values, standardized)
Predicted_values = predict(lm5, newdata = data4)
standardized = rstandard(lm5)
plot(Predicted_values, standardized)
Predicted_values = predict(lm4, newdata = data4)
standardized = rstandard(lm4)
plot(Predicted_values, standardized)
(r <- resid(lm4))
(pr <- resid(lm4)/(1 - lm.influence(lm4)$hat))
sum(r^2)
press<- sum(pr^2) #PRESS residual is 321.22
(r <- resid(lm5))
(pr <- resid(lm5)/(1 - lm.influence(lm5)$hat))
sum(r^2)
press<- sum(pr^2) #PRESS residual is 3692
press
lm4 <- lm(y ~ data4$x6, data=data4) #Run the linear regression
lm5 <- lm(y ~ data4$x7, data=data4) #Run the linear regression
(r <- resid(lm4))
(pr <- resid(lm4)/(1 - lm.influence(lm4)$hat))
sum(r^2)
press<- sum(pr^2) #PRESS residual is 3692
(r <- resid(lm5))
(pr <- resid(lm5)/(1 - lm.influence(lm5)$hat))
sum(r^2)
press<- sum(pr^2) #PRESS residual is 3692
summary(lm4)
summary(lm5)
data5 <- as.data.frame(read_excel("data-table-B16-1.xls"))
data5 <- as.data.frame(read_excel("data-table-B16-1.xls"))
lm6 <- lm(data5$LifeExp ~ data5$`People-per-TV` + data5$`People-per-Dr`)
lm7 <- lm(data5$LifeExpMale ~ data5$`People-per-TV` + data5$`People-per-Dr`)
lm8 <- lm(data5$LifeExpFemale ~ data5$`People-per-TV` + data5$`People-per-Dr`)
qqnorm(rstudent(lm6))
qqline(rstudent(lm6))
qqnorm(rstudent(lm7))
qqline(rstudent(lm7))
qqnorm(rstudent(lm8))
qqline(rstudent(lm8))
qqnorm(rstudent(lm7))
qqline(rstudent(lm7))
qqnorm(rstudent(lm6))
qqline(rstudent(lm6))
data6 <- as.data.frame(read_excel("data-table-B20.xls"))
lm8 <- lm(y ~ ., data=data6)
lm9 <- lm(y ~ ., data=data6)
qqnorm(rstudent(lm9))
qqline(rstudent(lm9))
Predicted_values = predict(lm9, newdata = data6)
standardized = rstandard(lm9)
plot(Predicted_values, standardized)
summary(lm9)
View(data6)
lm9 <- lm(y ~ x1 + x2 + x3, data=data6)
lm10 <- lm(y ~ x1 + x2 + x3, data=data6)
qqnorm(rstudent(lm10))
qqline(rstudent(lm10))
lm9 <- lm(y ~ ., data=data6)
qqnorm(rstudent(lm9))
qqline(rstudent(lm9))
Predicted_values = predict(lm10, newdata = data6)
standardized = rstandard(lm10)
plot(Predicted_values, standardized)
plot(data6$y, data6$x1)
plot(data6$x1, data6$y)
plot(data6$x2, data6$y)
plot(data6$x3, data6$y)
plot(data6$x4, data6$y)
plot(data6$x5, data6$y)
temperaturek <- c(273, 283, 293, 303, 313, 323, 333, 343, 353, 363, 373)
vapor <- c(4.6, 9.2, 17.5, 31.8, 55.3, 92.5, 149.4, 233.7, 355.1, 525.8, 760)
dat <- data.frame(temperaturek, vapor)
plot(dat$temperaturek, dat$vapor)
lm11 <- lm(dat$vapor <- dat$temperaturek)
lm11 <- lm(dat$vapor ~ dat$temperaturek)
summary(lm11)
qqnorm(rstudent(lm11))
qqline(rstudent(lm11))
plot(dat$Month, standardized)
Predicted_values = predict(lm11, newdata = dat)
standardized = rstandard(lm11)
plot(Predicted_values, standardized)
dat$inversetemp <- 1/dat$temperaturek
View(dat)
dat$inversetemp <- e^1/dat$temperaturek
dat$inversetemp <- (2.732)^1/dat$temperaturek
View(dat)
temperaturek <- c(273, 283, 293, 303, 313, 323, 333, 343, 353, 363, 373)
vapor <- c(4.6, 9.2, 17.5, 31.8, 55.3, 92.5, 149.4, 233.7, 355.1, 525.8, 760)
dat <- data.frame(temperaturek, vapor)
dat$inversetemp <- (2.732)^(-1/dat$temperaturek)
View(dat)
lm12 <- lm(dat$vapor <- dat$inversetemp)
lm12 <- lm(dat$vapor ~ dat$inversetemp)
qqnorm(rstudent(lm12))
qqline(rstudent(lm12))
Predicted_values = predict(lm12, newdata = dat)
standardized = rstandard(lm12)
plot(Predicted_values, standardized)
defectsper1000 <- c(13, 16.1, 14.5, 17.8, 22, 27.4, 16.8, 34.2, 65.6, 49.2, 66.2, 81.2, 87.4, 114.5)
weeks <- c(4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17)
dat <- data.frame(defectsper1000, weeks)
lm14 <- lm(dat$defectsper1000 <- dat$weeks)
lm14 <- lm(dat$defectsper1000 ~ dat$weeks)
qqnorm(rstudent(lm14))
qqline(rstudent(lm14))
Predicted_values = predict(lm14, newdata = dat)
standardized = rstandard(lm14)
plot(Predicted_values, standardized)
library(MASS)
boxcox(lm14)
plot(Predicted_values, standardized)
plot(dat$weeks, dat$defectsper1000)
View(dat)
defectsper1000 <- c(13, 16.1, 14.5, 17.8, 22, 27.4, 16.8, 34.2, 65.6, 49.2, 66.2, 81.2, 87.4, 114.5)
weeks <- c(4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17)
dat <- data.frame(defectsper1000, weeks)
View(dat)
lm14 <- lm(dat$defectsper1000 ~ dat$weeks)
qqnorm(rstudent(lm14))
qqline(rstudent(lm14))
Predicted_values = predict(lm14, newdata = dat)
standardized = rstandard(lm14)
plot(Predicted_values, standardized)
library(MASS)
boxcox(lm14)
plot(dat$weeks, dat$defectsper1000)
dat$lndefects <- ln(dat$defectsper1000)
ln(5)
log(5)
dat$lndefects <- log(dat$defectsper1000)
lm15 <- lm(dat$lndefects ~ dat$weeks)
qqnorm(rstudent(lm15))
qqline(rstudent(lm15))
Predicted_values = predict(lm15, newdata = dat)
standardized = rstandard(lm15)
plot(Predicted_values, standardized)
data10 <- as.data.frame(read_excel("data-table-B20.xls"))
lm15 <- lm(y ~ ., data = data10)
lm16 <- lm(y ~ ., data = data10)
qqnorm(rstudent(lm16))
qqline(rstudent(lm16))
Predicted_values = predict(lm16, newdata = dat)
standardized = rstandard(lm16)
plot(Predicted_values, standardized)
Predicted_values = predict(lm16, newdata = data10)
standardized = rstandard(lm16)
plot(Predicted_values, standardized)
lm16 <- lm(y ~ x1 + x2 + x3, data = data10)
data10 <- as.data.frame(read_excel("data-table-B20.xls"))
lm16 <- lm(y ~ x1 + x2 + x3, data = data10)
qqnorm(rstudent(lm16))
qqline(rstudent(lm16))
Predicted_values = predict(lm16, newdata = data10)
standardized = rstandard(lm16)
plot(Predicted_values, standardized)
boxcox(lm16)
data10$lny <- log(data10$y)
lm17 <- lm(data10$lny <- data10$x1 + data10$x2 + data10$x3)
lm17 <- lm(data10$lny ~ data10$x1 + data10$x2 + data10$x3)
qqnorm(rstudent(lm17))
qqline(rstudent(lm17))
Predicted_values = predict(lm17, newdata = data10)
standardized = rstandard(lm17)
plot(Predicted_values, standardized)
